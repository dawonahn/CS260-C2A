Traceback (most recent call last):
  File "/home/dahn017/courses/cs260/CS260-MMA/src/main.py", line 55, in <module>
    main()
  File "/home/dahn017/courses/cs260/CS260-MMA/src/main.py", line 51, in main
    results = train(dataset, config)
  File "/home/dahn017/courses/cs260/CS260-MMA/src/train.py", line 63, in train
    loss = criterion(pred, batch_y_train.reshape(-1, 1))
  File "/home/dahn017/miniconda3/envs/tensor/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dahn017/miniconda3/envs/tensor/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 619, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/home/dahn017/miniconda3/envs/tensor/lib/python3.9/site-packages/torch/nn/functional.py", line 3095, in binary_cross_entropy
    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cpu!